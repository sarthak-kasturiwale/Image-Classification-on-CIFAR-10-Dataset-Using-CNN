{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Classification-on-CIFAR-10-Dataset-Using-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image classification is a fascinating deep learning project.\n",
    "- In this project, we will build a convolution neural network in Keras with python on a CIFAR-10 dataset to Recognise Various Objects and classify them into different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The CIFAR-10 dataset consists of 60000 32×32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "- You can download the dataset from https://www.cs.utoronto.ca/~kriz/cifar.html\n",
    "\n",
    "- Extract the data to a folder and in the same folder create a script to open your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in the official data. \n",
    "\n",
    "2.  The dataset is broken into batches to prevent our machine from running out of memory. The CIFAR-10 dataset consists of 5 batches, named data_batch_1, data_batch_2, etc. As stated in the official web site, each file packs the data using pickle module in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Understanding the Original Data:**\n",
    "    - The original one batch data is (10000 x 3072) matrix expressed in numpy array. \n",
    "    \n",
    "    - The number of columns, (10000), indicates the number of sample data. \n",
    "    \n",
    "    - As stated in the CIFAR-10/CIFAR-100 dataset, the row vector, (3072) represents an color image of 32x32 pixels.\n",
    "    \n",
    "    - Since this project is going to use CNN for the classification tasks, the original row vector is not appropriate.\n",
    "    \n",
    "    - In order to feed an image data into a CNN model, the dimension of the input tensor should be:\n",
    "        1. (width x height x num_channel) or \n",
    "        2. (num_channel x width x height)\n",
    "        \n",
    "    - It depends on your choice (check out the tensorflow conv2d). I am going to use the first choice because the default choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **How to reshape into a such form?**\n",
    "\n",
    "- The row vector for an image has the exact same number of elements if you calculate 32*32*3 == 3072. In order to reshape the row vector into (width x height x num_channel) form, there are two steps required. \n",
    "\n",
    "    1. The first step is to use reshape function, and the second step is to use transpose function in numpy. The following direction is described in a logical concept.\n",
    "\n",
    "        - Divide the row vector into 3 pieces, where each piece means each color channel.\n",
    "            - the resulting array has (3 x 1024) matrix, which makes (10000 x 3 x 1024) tensor in total.\n",
    "        - Divide the each 3 pieces further by 32. 32 is width and height of an image.\n",
    "            - this results in (3 x 32 x 32), which makes (10000 x 3 x 32 x 32) tensor in total\n",
    "\n",
    "    2. This is not the end of story yet. Now, one image data is represented as (num_channel, width, height) form. However, this is not the shape tensorflow / keras are expecting. They are expecting different shape (width, height, num_channel) instead. We need to swap the order of each axes, and that is where transpose comes in.\n",
    "\n",
    "        - The transpose can take a list of axes, and each value specifies an index of dimension it wants to move. \n",
    "            - For example, calling transpose with argument (1, 2, 0) in an numpy array of (num_channel, width, height) will return a new numpy array of (width, height, num_channel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **The label classes in the dataset are:**\n",
    "\n",
    "- airplane \n",
    "- automobile \n",
    "- bird \n",
    "- cat \n",
    "- deer \n",
    "- dog \n",
    "- frog \n",
    "- horse \n",
    "- ship \n",
    "- truck\n",
    "\n",
    "6. The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I choose CIFAR 10 dataset to experiment my deep learning theory for the below reasons:**\n",
    "\n",
    "1. CIFAR 10 is a bit challenging since it has 60K images, which is a lot for a begginer.\n",
    "2. The images are compressed so that they can be trained with less computational power.\n",
    "3. CIFAR 10 is very popular so that if I was struck at some point I can easily get lot of help from community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPool2D, AveragePooling2D, ZeroPadding2D, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Other Files\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing the data to a format acceptable by the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle the dataset\n",
    "def unpickle_all_data(directory):\n",
    "    \n",
    "    # Initialize the variables\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    \n",
    "    # Iterate through all files that we want to train and test\n",
    "    \n",
    "    # Train is separated into batches\n",
    "    for filename in listdir(directory):\n",
    "        if isfile(join(directory, filename)):\n",
    "            \n",
    "            # The train data\n",
    "            if 'data_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Open the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding = 'bytes')\n",
    "\n",
    "                if 'data' not in train:\n",
    "                    train['data'] = data[b'data']\n",
    "                    train['labels'] = np.array(data[b'labels'])\n",
    "                else:\n",
    "                    train['data'] = np.concatenate((train['data'], data[b'data']))\n",
    "                    train['labels'] = np.concatenate((train['labels'], data[b'labels']))\n",
    "                    \n",
    "            # The test data\n",
    "            elif 'test_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Open the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding='bytes')\n",
    "                \n",
    "                test['data'] = data[b'data']\n",
    "                test['labels'] = data[b'labels']\n",
    "    \n",
    "    # Manipulate the data to the propper format\n",
    "    for image in train['data']:\n",
    "        train_x.append(np.transpose(np.reshape(image,(3,32,32)), (1,2,0)))\n",
    "        \n",
    "    train_y = [label for label in train['labels']]\n",
    "    \n",
    "    for image in test['data']:\n",
    "        test_x.append(np.transpose(np.reshape(image,(3,32,32)), (1,2,0)))\n",
    "        \n",
    "    test_y = [label for label in test['labels']]\n",
    "    \n",
    "    # Transform the data to np array format\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handing file: data_batch_1\n",
      "Handing file: data_batch_2\n",
      "Handing file: data_batch_3\n",
      "Handing file: data_batch_4\n",
      "Handing file: data_batch_5\n",
      "Handing file: test_batch\n"
     ]
    }
   ],
   "source": [
    "# Run the function with and include the folder where the data are\n",
    "(x_train, y_train), (x_test, y_test) = unpickle_all_data(os.getcwd() + '/cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the data generated into seperate files \n",
    "with open('x_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('x_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation files\n",
    "\n",
    "files = ['x_train.pickle', 'y_train.pickle',\n",
    "         'x_test.pickle', 'y_test.pickle']\n",
    "\n",
    "# Load training samples\n",
    "with open(files[0], 'rb') as img_file:\n",
    "    x_train = pickle.load(img_file, encoding='bytes')\n",
    "    \n",
    "# Load training labels\n",
    "with open(files[1], 'rb') as lb_file:\n",
    "    y_train = pickle.load(lb_file, encoding='bytes')\n",
    "    \n",
    "# Load validation samples\n",
    "with open(files[2], 'rb') as img_file_v:\n",
    "    x_test = pickle.load(img_file_v, encoding='bytes')\n",
    "    \n",
    "# Load validation labels\n",
    "with open(files[3], 'rb') as lb_file_v:\n",
    "    y_test = pickle.load(lb_file_v, encoding='bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transofrm the Features to a float32 type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the input features\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Applying One-hot Encoding to lables\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "2. Max Pool layer with size 2×2\n",
    "3. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "4. Max Pool layer with size 2×2\n",
    "5. Flatten layer\n",
    "6. Fully connected layer with 256 units and a rectifier activation function as relu\n",
    "7. Fully connected output layer with 10 units and a softmax activation function\n",
    "8. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_1\n",
    "Model_1 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_1.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_1.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_1.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_1.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Flattening\n",
    "Model_1.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_1.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "# Output Layer\n",
    "Model_1.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_1\n",
    "Model_1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 307,882\n",
      "Trainable params: 307,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4211 - accuracy: 0.4901 - val_loss: 1.1609 - val_accuracy: 0.5913\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0848 - accuracy: 0.6189 - val_loss: 1.0389 - val_accuracy: 0.6319\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.9433 - accuracy: 0.6688 - val_loss: 1.0409 - val_accuracy: 0.6405\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.8261 - accuracy: 0.7088 - val_loss: 0.9592 - val_accuracy: 0.6691\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7319 - accuracy: 0.7454 - val_loss: 0.9427 - val_accuracy: 0.6758\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6379 - accuracy: 0.7780 - val_loss: 0.9429 - val_accuracy: 0.6721\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5608 - accuracy: 0.8040 - val_loss: 0.9570 - val_accuracy: 0.6866\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4798 - accuracy: 0.8319 - val_loss: 0.9779 - val_accuracy: 0.6992\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4080 - accuracy: 0.8564 - val_loss: 1.0252 - val_accuracy: 0.6999\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3434 - accuracy: 0.8786 - val_loss: 1.0846 - val_accuracy: 0.6936\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2824 - accuracy: 0.9022 - val_loss: 1.2070 - val_accuracy: 0.6877\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2384 - accuracy: 0.9157 - val_loss: 1.3322 - val_accuracy: 0.6892\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2004 - accuracy: 0.9301 - val_loss: 1.5069 - val_accuracy: 0.6762\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1670 - accuracy: 0.9414 - val_loss: 1.5499 - val_accuracy: 0.6792\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.1482 - accuracy: 0.9478 - val_loss: 1.7104 - val_accuracy: 0.6812\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.1288 - accuracy: 0.9550 - val_loss: 1.8070 - val_accuracy: 0.6765\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.1168 - accuracy: 0.9596 - val_loss: 1.9806 - val_accuracy: 0.6711\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.1108 - accuracy: 0.9607 - val_loss: 2.0549 - val_accuracy: 0.6782\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.1034 - accuracy: 0.9639 - val_loss: 2.1737 - val_accuracy: 0.6702\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 2.1755 - val_accuracy: 0.6786\n"
     ]
    }
   ],
   "source": [
    "Model_1_result = Model_1.fit(x_train, y_train, epochs = 20, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 2.1755 - accuracy: 0.6786\n",
      "Test Loss is : 2.175469160079956 and the Test Accuracy is: 0.678600013256073\n"
     ]
    }
   ],
   "source": [
    "Model_1_evaluation = Model_1.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_1_evaluation[0], Model_1_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using our base model we are able to get 96.80% training accuracy and 67.86% test accuracy, which is not that great but it is not bad either so we use our very simple model. \n",
    "\n",
    "2. If you observe the model training log above you can see that Validation loss is increasing a lot which means our model is overfitting. That means our model performs good on the training data but fails to generalize on the unseen data. \n",
    "\n",
    "3. Lets try to reduce overfitting. How to reduce Overfitting?\n",
    "    1. Add more data\n",
    "    2. Decrease model complexity\n",
    "    3. Apply regularization\n",
    "\n",
    "4. Option 1 and 2 are not a good fit in our case, since getting more data is very tough and out model is not that complex to reduce the architecture. \n",
    "\n",
    "5. So lets regularize the model. In deep learning drop out is very good form of regularization. Dropout is a regularization method that approximates training a large number of neural networks with different architectures in parallel.\n",
    "\n",
    "6. Drop out literally means we gonna drop some of the neural units randomly from our network, which forces the next layer to learn the patterns again. In this way our model will become more robust and generalizes well. \n",
    "\n",
    "7. Lets try to add drop out after each CNN layer + MaxPool Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model 2 with Drop outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "2. Max Pool layer with size 2×2\n",
    "3. Dropout set to 25%\n",
    "4. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "5. Max Pool layer with size 2×2\n",
    "6. Dropout set to 25%\n",
    "7. Flatten layer\n",
    "8. Fully connected layer with 256 units and a rectifier activation function as relu\n",
    "9. Dropout set to 50%\n",
    "10. Fully connected output layer with 10 units and a softmax activation function\n",
    "11. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_2\n",
    "Model_2 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_2.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_2.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_2.add(Dropout(0.25))\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_2.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_2.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_2.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "Model_2.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_2.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_2.add(Dropout(0.50))\n",
    "\n",
    "# Output Layer\n",
    "Model_2.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_1\n",
    "Model_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 307,882\n",
      "Trainable params: 307,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 1.6184 - accuracy: 0.4079 - val_loss: 1.3002 - val_accuracy: 0.5475\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 1.3126 - accuracy: 0.5340 - val_loss: 1.1390 - val_accuracy: 0.6085\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.1929 - accuracy: 0.5780 - val_loss: 1.0325 - val_accuracy: 0.6439\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.1296 - accuracy: 0.6022 - val_loss: 1.0339 - val_accuracy: 0.6420\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 1.0834 - accuracy: 0.6179 - val_loss: 0.9678 - val_accuracy: 0.6591\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.0469 - accuracy: 0.6336 - val_loss: 0.9929 - val_accuracy: 0.6484\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.0173 - accuracy: 0.6432 - val_loss: 0.9261 - val_accuracy: 0.6768\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.9982 - accuracy: 0.6469 - val_loss: 0.8926 - val_accuracy: 0.6858\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.9721 - accuracy: 0.6575 - val_loss: 0.8875 - val_accuracy: 0.6982\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9535 - accuracy: 0.6627 - val_loss: 0.9055 - val_accuracy: 0.6882\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9333 - accuracy: 0.6716 - val_loss: 0.8349 - val_accuracy: 0.7130\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9254 - accuracy: 0.6741 - val_loss: 0.8442 - val_accuracy: 0.7111\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9039 - accuracy: 0.6823 - val_loss: 0.8233 - val_accuracy: 0.7166\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8905 - accuracy: 0.6871 - val_loss: 0.8269 - val_accuracy: 0.7171\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.8911 - accuracy: 0.6895 - val_loss: 0.8427 - val_accuracy: 0.7082\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.8688 - accuracy: 0.6948 - val_loss: 0.8146 - val_accuracy: 0.7186\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.8643 - accuracy: 0.6975 - val_loss: 0.8175 - val_accuracy: 0.7198\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.8504 - accuracy: 0.7021 - val_loss: 0.8485 - val_accuracy: 0.7089\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.8429 - accuracy: 0.7037 - val_loss: 0.8149 - val_accuracy: 0.7191\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8323 - accuracy: 0.7068 - val_loss: 0.8086 - val_accuracy: 0.7246\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8301 - accuracy: 0.7082 - val_loss: 0.8262 - val_accuracy: 0.7155\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8187 - accuracy: 0.7127 - val_loss: 0.8036 - val_accuracy: 0.7244\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.8183 - accuracy: 0.7124 - val_loss: 0.7896 - val_accuracy: 0.7300\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.8088 - accuracy: 0.7145 - val_loss: 0.7890 - val_accuracy: 0.7299\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8045 - accuracy: 0.7160 - val_loss: 0.7763 - val_accuracy: 0.7279\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.7963 - accuracy: 0.7204 - val_loss: 0.7871 - val_accuracy: 0.7277\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.7927 - accuracy: 0.7205 - val_loss: 0.7715 - val_accuracy: 0.7351\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7876 - accuracy: 0.7231 - val_loss: 0.7727 - val_accuracy: 0.7347\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.7822 - accuracy: 0.7241 - val_loss: 0.7744 - val_accuracy: 0.7337\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.7720 - accuracy: 0.7274 - val_loss: 0.7889 - val_accuracy: 0.7297\n"
     ]
    }
   ],
   "source": [
    "Model_2_result = Model_2.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.7889 - accuracy: 0.7297\n",
      "Test Loss is : 0.788870632648468 and the Test Accuracy is: 0.7297000288963318\n"
     ]
    }
   ],
   "source": [
    "Model_2_evaluation = Model_2.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_2_evaluation[0], Model_2_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Thats cool, Improvememt of validation accuracy from 67 to 72.97% is a good start, lets try to add more number of layers with increase in the number of filters. \n",
    "2. Also looks like we can train out model for more number of epochs since our validation loss is in control. Thanks to drop outs!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: with Dropouts, More Layers and More Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "2. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "3. Max Pool layer with size 2×2\n",
    "4. Dropout set to 40%\n",
    "5. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "6. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu\n",
    "7. Max Pool layer with size 2×2\n",
    "8. Dropout set to 40%\n",
    "9. Flatten layer\n",
    "10. Fully connected layer with 512 units and a rectifier activation function as relu\n",
    "11. Fully connected layer with 512 units and a rectifier activation function as relu\n",
    "12. Dropout set to 50%\n",
    "13. Fully connected output layer with 10 units and a softmax activation function\n",
    "14. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_3\n",
    "Model_3 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_3.add(Conv2D(filters = 64, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu'))\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_3.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_3.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_3.add(Dropout(0.40))\n",
    "\n",
    "# Adding 3rd Convolutional Layer\n",
    "Model_3.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "# Adding 4th Convolutional Layer\n",
    "Model_3.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_3.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_3.add(Dropout(0.40))\n",
    "\n",
    "# Flattening\n",
    "Model_3.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_3.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "# Full Connection\n",
    "Model_3.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_3.add(Dropout(0.50))\n",
    "\n",
    "# Output Layer\n",
    "Model_3.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_3\n",
    "Model_3.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,166,858\n",
      "Trainable params: 2,166,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 329s 211ms/step - loss: 1.5861 - accuracy: 0.4128 - val_loss: 1.2935 - val_accuracy: 0.5227\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 1.2252 - accuracy: 0.5636 - val_loss: 1.0596 - val_accuracy: 0.6282\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 330s 211ms/step - loss: 1.0735 - accuracy: 0.6223 - val_loss: 0.9755 - val_accuracy: 0.6538\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 333s 213ms/step - loss: 0.9861 - accuracy: 0.6542 - val_loss: 0.8825 - val_accuracy: 0.6954\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 326s 209ms/step - loss: 0.9178 - accuracy: 0.6780 - val_loss: 0.8302 - val_accuracy: 0.7117\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 0.8653 - accuracy: 0.6959 - val_loss: 0.7946 - val_accuracy: 0.7255\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 0.8264 - accuracy: 0.7129 - val_loss: 0.7843 - val_accuracy: 0.7293\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 0.7899 - accuracy: 0.7241 - val_loss: 0.7946 - val_accuracy: 0.7289\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 329s 210ms/step - loss: 0.7642 - accuracy: 0.7335 - val_loss: 0.7416 - val_accuracy: 0.7462\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 329s 211ms/step - loss: 0.7384 - accuracy: 0.7420 - val_loss: 0.8576 - val_accuracy: 0.7136\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 339s 217ms/step - loss: 0.7241 - accuracy: 0.7464 - val_loss: 0.7515 - val_accuracy: 0.7429\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 329s 211ms/step - loss: 0.7047 - accuracy: 0.7550 - val_loss: 0.7326 - val_accuracy: 0.7533\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 329s 210ms/step - loss: 0.6853 - accuracy: 0.7615 - val_loss: 0.7103 - val_accuracy: 0.7575\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 0.6701 - accuracy: 0.7665 - val_loss: 0.7351 - val_accuracy: 0.7560\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 333s 213ms/step - loss: 0.6622 - accuracy: 0.7709 - val_loss: 0.7352 - val_accuracy: 0.7523\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 329s 210ms/step - loss: 0.6493 - accuracy: 0.7740 - val_loss: 0.6859 - val_accuracy: 0.7697\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 332s 213ms/step - loss: 0.6297 - accuracy: 0.7808 - val_loss: 0.7374 - val_accuracy: 0.7643\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 338s 216ms/step - loss: 0.6208 - accuracy: 0.7827 - val_loss: 0.7518 - val_accuracy: 0.7513\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 0.6083 - accuracy: 0.7880 - val_loss: 0.7084 - val_accuracy: 0.7645\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 0.6091 - accuracy: 0.7893 - val_loss: 0.7443 - val_accuracy: 0.7579\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 0.5860 - accuracy: 0.7956 - val_loss: 0.7315 - val_accuracy: 0.7562\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 0.5868 - accuracy: 0.7975 - val_loss: 0.7095 - val_accuracy: 0.7700\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 329s 211ms/step - loss: 0.5671 - accuracy: 0.8022 - val_loss: 0.7375 - val_accuracy: 0.7584\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 359s 229ms/step - loss: 0.5663 - accuracy: 0.8039 - val_loss: 0.7244 - val_accuracy: 0.7631\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 0.5654 - accuracy: 0.8048 - val_loss: 0.7110 - val_accuracy: 0.7673\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 0.5507 - accuracy: 0.8096 - val_loss: 0.6881 - val_accuracy: 0.7716\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 345s 221ms/step - loss: 0.5414 - accuracy: 0.8116 - val_loss: 0.7392 - val_accuracy: 0.7702\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 341s 218ms/step - loss: 0.5366 - accuracy: 0.8148 - val_loss: 0.7195 - val_accuracy: 0.7626\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 341s 218ms/step - loss: 0.5242 - accuracy: 0.8195 - val_loss: 0.7617 - val_accuracy: 0.7576\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 358s 229ms/step - loss: 0.5293 - accuracy: 0.8174 - val_loss: 0.7137 - val_accuracy: 0.7696\n"
     ]
    }
   ],
   "source": [
    "Model_3_result = Model_3.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 16s 51ms/step - loss: 0.7137 - accuracy: 0.7696\n",
      "Test Loss is : 0.7137004137039185 and the Test Accuracy is: 0.769599974155426\n"
     ]
    }
   ],
   "source": [
    "Model_3_evaluation = Model_3.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_3_evaluation[0], Model_3_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adding more layers and increasing droup out from 0.25 to 0.4 resulted in 76.95 % accuracy which a good improvement, so lets try increase layers.\n",
    "2. Also dont just blindly add more layers. If you keep adding more CNN's we will lose the data as data will be reduced in size due to convolution. So when we use small size images its good idea to limit the number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: with Increased Dropouts, More Layers, More Filters, Padding and Using He Kernel Initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "2. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "3. Max Pool layer with size 2×2\n",
    "4. Dropout set to 20%\n",
    "5. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "6. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "7. Max Pool layer with size 2×2\n",
    "8. Dropout set to 25%\n",
    "9. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "10. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "11. Max Pool layer with size 2×2\n",
    "12. Dropout set to 30%\n",
    "13. Flatten layer\n",
    "14. Fully connected layer with 128 units and a rectifier activation function as relu\n",
    "15. Dropout set to 40%\n",
    "16. Fully connected output layer with 10 units and a softmax activation function\n",
    "17. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_4\n",
    "Model_4 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_4.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_4.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', kernel_initializer = 'he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_4.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_4.add(Dropout(0.20))\n",
    "\n",
    "# Adding 3rd Convolutional Layer\n",
    "Model_4.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding 4th Convolutional Layer\n",
    "Model_4.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_4.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_4.add(Dropout(0.25))\n",
    "\n",
    "# Adding 5th Convolutional Layer\n",
    "Model_4.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding 6th Convolutional Layer\n",
    "Model_4.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Max Pooling\n",
    "Model_4.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_4.add(Dropout(0.30))\n",
    "\n",
    "# Flattening\n",
    "Model_4.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_4.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_4.add(Dropout(0.40))\n",
    "\n",
    "# Output Layer\n",
    "Model_4.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_3\n",
    "Model_4.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 289s 185ms/step - loss: 1.6756 - accuracy: 0.3804 - val_loss: 1.2949 - val_accuracy: 0.5259\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 293s 188ms/step - loss: 1.2487 - accuracy: 0.5511 - val_loss: 1.0662 - val_accuracy: 0.6204\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 277s 177ms/step - loss: 1.0664 - accuracy: 0.6242 - val_loss: 0.8718 - val_accuracy: 0.6905\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 290s 186ms/step - loss: 0.9545 - accuracy: 0.6692 - val_loss: 0.8553 - val_accuracy: 0.7058\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 288s 184ms/step - loss: 0.8741 - accuracy: 0.6972 - val_loss: 0.7705 - val_accuracy: 0.7350\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.8247 - accuracy: 0.7156 - val_loss: 0.7402 - val_accuracy: 0.7502\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 290s 186ms/step - loss: 0.7800 - accuracy: 0.7310 - val_loss: 0.7358 - val_accuracy: 0.7513\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 282s 180ms/step - loss: 0.7524 - accuracy: 0.7418 - val_loss: 0.6901 - val_accuracy: 0.7631\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 277s 177ms/step - loss: 0.7228 - accuracy: 0.7509 - val_loss: 0.6911 - val_accuracy: 0.7681\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 286s 183ms/step - loss: 0.7023 - accuracy: 0.7565 - val_loss: 0.6978 - val_accuracy: 0.7670\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.6807 - accuracy: 0.7645 - val_loss: 0.6396 - val_accuracy: 0.7861\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 281s 180ms/step - loss: 0.6746 - accuracy: 0.7696 - val_loss: 0.6735 - val_accuracy: 0.7820\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 275s 176ms/step - loss: 0.6580 - accuracy: 0.7747 - val_loss: 0.6352 - val_accuracy: 0.7843\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.6495 - accuracy: 0.7767 - val_loss: 0.6496 - val_accuracy: 0.7794\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 305s 195ms/step - loss: 0.6336 - accuracy: 0.7809 - val_loss: 0.6334 - val_accuracy: 0.7866\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 296s 190ms/step - loss: 0.6184 - accuracy: 0.7878 - val_loss: 0.6635 - val_accuracy: 0.7796\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 287s 184ms/step - loss: 0.6172 - accuracy: 0.7857 - val_loss: 0.6477 - val_accuracy: 0.7835\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 284s 182ms/step - loss: 0.6058 - accuracy: 0.7915 - val_loss: 0.6302 - val_accuracy: 0.7932\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 314s 201ms/step - loss: 0.5932 - accuracy: 0.7956 - val_loss: 0.6374 - val_accuracy: 0.7979\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 0.5896 - accuracy: 0.7975 - val_loss: 0.6238 - val_accuracy: 0.7979\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5873 - accuracy: 0.7995 - val_loss: 0.6285 - val_accuracy: 0.7995\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5834 - accuracy: 0.7980 - val_loss: 0.6162 - val_accuracy: 0.8010\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 268s 172ms/step - loss: 0.5755 - accuracy: 0.8013 - val_loss: 0.6007 - val_accuracy: 0.8045\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5699 - accuracy: 0.8058 - val_loss: 0.5917 - val_accuracy: 0.8065\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 267s 171ms/step - loss: 0.5647 - accuracy: 0.8070 - val_loss: 0.6075 - val_accuracy: 0.8053\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5665 - accuracy: 0.8043 - val_loss: 0.6251 - val_accuracy: 0.8017\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 266s 170ms/step - loss: 0.5637 - accuracy: 0.8083 - val_loss: 0.6237 - val_accuracy: 0.8082\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 266s 170ms/step - loss: 0.5508 - accuracy: 0.8125 - val_loss: 0.6181 - val_accuracy: 0.8030\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 266s 170ms/step - loss: 0.5598 - accuracy: 0.8077 - val_loss: 0.6344 - val_accuracy: 0.7949\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 0.5436 - accuracy: 0.8116 - val_loss: 0.6353 - val_accuracy: 0.8025\n"
     ]
    }
   ],
   "source": [
    "Model_4_result = Model_4.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 32ms/step - loss: 0.6353 - accuracy: 0.8025\n",
      "Test Loss is : 0.6353070735931396 and the Test Accuracy is: 0.8025000095367432\n"
     ]
    }
   ],
   "source": [
    "Model_4_evaluation = Model_4.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_4_evaluation[0], Model_4_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  If you see the behaviour our model, we can still train our model longer since validation loss is not getting worse, ofcourse there are some fluctuations and distrotions in loss. \n",
    "2. Either we can run it for 200 epochs or more or simply leave it here and work on how to control those fluctuations and then train our model for more number of epochs. \n",
    "3. Lets go for option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: with Increased Dropouts, More Layers, More Filters, Padding, Using He Kernel Initializer and using Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch normalization works just the same way as we normalize the input data where we divided the x_train/255. What we are trying to do there is we are arranging all the features in same scale so that model converges easily and we can reduce the distrotions. Our input layer is lucky enough to have everything in same scale why not the rest of the layers?\n",
    "\n",
    "- This is what exactly we do in batch normalization, when ever we passs the CNN throuh a batch normalization layer we are normalizing the weights so that our model will be stable and we can train model longer and also use larger learning rate.\n",
    "\n",
    "- Also the kind of normalization we use is batch normalization which means we compute mean and varience for each mini batch not the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "2. Add batch Normalization\n",
    "3. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "4. Add batch Normalization\n",
    "5. Max Pool layer with size 2×2\n",
    "6. Dropout set to 20%\n",
    "7. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "8. Add batch Normalization\n",
    "9. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "10. Add batch Normalization\n",
    "11. Max Pool layer with size 2×2\n",
    "12. Dropout set to 30%\n",
    "13. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "14. Add batch Normalization\n",
    "15. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "16. Add batch Normalization\n",
    "17. Max Pool layer with size 2×2\n",
    "18. Dropout set to 40%\n",
    "19. Flatten layer\n",
    "20. Fully connected layer with 128 units and a rectifier activation function as relu\n",
    "21. Add batch Normalization\n",
    "22. Dropout set to 50%\n",
    "23. Fully connected output layer with 10 units and a softmax activation function\n",
    "24. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_5\n",
    "Model_5 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_5.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu', padding = 'same',\n",
    "                   kernel_initializer='he_uniform'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_5.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_5.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_5.add(Dropout(0.20))\n",
    "\n",
    "# Adding 3rd Convolutional Layer\n",
    "Model_5.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Adding 4th Convolutional Layer\n",
    "Model_5.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_5.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_5.add(Dropout(0.3))\n",
    "\n",
    "# Adding 5th Convolutional Layer\n",
    "Model_5.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Adding 6th Convolutional Layer\n",
    "Model_5.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_5.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_5.add(Dropout(0.40))\n",
    "\n",
    "# Flattening\n",
    "Model_5.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_5.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_5.add(BatchNormalization())\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_5.add(Dropout(0.50))\n",
    "\n",
    "# Output Layer\n",
    "Model_5.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_3\n",
    "Model_5.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 426s 273ms/step - loss: 1.5620 - accuracy: 0.4554 - val_loss: 1.2058 - val_accuracy: 0.5712\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 488s 312ms/step - loss: 1.0762 - accuracy: 0.6214 - val_loss: 0.9316 - val_accuracy: 0.6681\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 517s 331ms/step - loss: 0.9113 - accuracy: 0.6843 - val_loss: 0.9145 - val_accuracy: 0.6808\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 507s 325ms/step - loss: 0.8154 - accuracy: 0.7189 - val_loss: 0.6550 - val_accuracy: 0.7738\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 442s 282ms/step - loss: 0.7245 - accuracy: 0.7521 - val_loss: 0.6886 - val_accuracy: 0.7604\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 480s 307ms/step - loss: 0.6696 - accuracy: 0.7725 - val_loss: 0.5845 - val_accuracy: 0.8000\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 430s 275ms/step - loss: 0.6263 - accuracy: 0.7883 - val_loss: 0.5560 - val_accuracy: 0.8058\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 420s 268ms/step - loss: 0.5847 - accuracy: 0.8015 - val_loss: 0.7196 - val_accuracy: 0.7618\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 416s 266ms/step - loss: 0.5512 - accuracy: 0.8125 - val_loss: 0.5201 - val_accuracy: 0.8220\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 413s 264ms/step - loss: 0.5238 - accuracy: 0.8233 - val_loss: 0.5306 - val_accuracy: 0.8220\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 418s 267ms/step - loss: 0.4982 - accuracy: 0.8319 - val_loss: 0.5055 - val_accuracy: 0.8296\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 418s 267ms/step - loss: 0.4810 - accuracy: 0.8369 - val_loss: 0.4983 - val_accuracy: 0.8307\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 411s 263ms/step - loss: 0.4586 - accuracy: 0.8435 - val_loss: 0.4720 - val_accuracy: 0.8422\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 413s 264ms/step - loss: 0.4443 - accuracy: 0.8476 - val_loss: 0.4651 - val_accuracy: 0.8458\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 414s 265ms/step - loss: 0.4298 - accuracy: 0.8536 - val_loss: 0.4865 - val_accuracy: 0.8408\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 411s 263ms/step - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4821 - val_accuracy: 0.8418\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 410s 262ms/step - loss: 0.4013 - accuracy: 0.8639 - val_loss: 0.4578 - val_accuracy: 0.8477\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 407s 261ms/step - loss: 0.3874 - accuracy: 0.8682 - val_loss: 0.4735 - val_accuracy: 0.8460\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 401s 256ms/step - loss: 0.3772 - accuracy: 0.8714 - val_loss: 0.4516 - val_accuracy: 0.8508\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 393s 251ms/step - loss: 0.3654 - accuracy: 0.8753 - val_loss: 0.4413 - val_accuracy: 0.8542\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 392s 251ms/step - loss: 0.3563 - accuracy: 0.8783 - val_loss: 0.4434 - val_accuracy: 0.8567\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 394s 252ms/step - loss: 0.3497 - accuracy: 0.8794 - val_loss: 0.4616 - val_accuracy: 0.8526\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 393s 252ms/step - loss: 0.3456 - accuracy: 0.8805 - val_loss: 0.4566 - val_accuracy: 0.8515\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 398s 254ms/step - loss: 0.3291 - accuracy: 0.8877 - val_loss: 0.4757 - val_accuracy: 0.8484\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 394s 252ms/step - loss: 0.3252 - accuracy: 0.8876 - val_loss: 0.4641 - val_accuracy: 0.8520\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 394s 252ms/step - loss: 0.3134 - accuracy: 0.8925 - val_loss: 0.4676 - val_accuracy: 0.8534\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 397s 254ms/step - loss: 0.3141 - accuracy: 0.8921 - val_loss: 0.4403 - val_accuracy: 0.8575\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 398s 255ms/step - loss: 0.3056 - accuracy: 0.8963 - val_loss: 0.4354 - val_accuracy: 0.8607\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 401s 257ms/step - loss: 0.3013 - accuracy: 0.8971 - val_loss: 0.4321 - val_accuracy: 0.8629\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 400s 256ms/step - loss: 0.2917 - accuracy: 0.9007 - val_loss: 0.4352 - val_accuracy: 0.8636\n"
     ]
    }
   ],
   "source": [
    "Model_5_result = Model_5.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step - loss: 0.4352 - accuracy: 0.8636\n",
      "Test Loss is : 0.43515413999557495 and the Test Accuracy is: 0.8636000156402588\n"
     ]
    }
   ],
   "source": [
    "Model_5_evaluation = Model_5.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_5_evaluation[0], Model_5_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adding batch normalizaton yeilds very good results and we are able to get 86.36% validation accuracy which is really good. \n",
    "2. Batch normalization made our average results into excellent results. Still there is a lot of improvement scope as the Benchmarks.ai website have achieved 99.37. So there is definitely a lot we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6: Image augmentation (Using Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "2. Add batch Normalization\n",
    "3. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "4. Add batch Normalization\n",
    "5. Max Pool layer with size 2×2\n",
    "6. Dropout set to 20%\n",
    "7. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "8. Add batch Normalization\n",
    "9. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "10. Add batch Normalization\n",
    "11. Max Pool layer with size 2×2\n",
    "12. Dropout set to 30%\n",
    "13. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "14. Add batch Normalization\n",
    "15. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function as relu, padding as same and kernel initializer as He.\n",
    "16. Add batch Normalization\n",
    "17. Max Pool layer with size 2×2\n",
    "18. Dropout set to 40%\n",
    "19. Flatten layer\n",
    "20. Fully connected layer with 128 units and a rectifier activation function as relu\n",
    "21. Add batch Normalization\n",
    "22. Dropout set to 50%\n",
    "23. Fully connected output layer with 10 units and a softmax activation function\n",
    "24. Compiling the Model with adam optimizer and metrices as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the Model_6\n",
    "Model_6 = Sequential()\n",
    "\n",
    "# Convolution\n",
    "Model_6.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (32,32,3), activation = 'relu', padding = 'same',\n",
    "                   kernel_initializer='he_uniform'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Adding 2nd Convolutional Layer\n",
    "Model_6.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_6.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_6.add(Dropout(0.20))\n",
    "\n",
    "# Adding 3rd Convolutional Layer\n",
    "Model_6.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Adding 4th Convolutional Layer\n",
    "Model_6.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_6.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_6.add(Dropout(0.3))\n",
    "\n",
    "# Adding 5th Convolutional Layer\n",
    "Model_6.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Adding 6th Convolutional Layer\n",
    "Model_6.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', kernel_initializer='he_uniform', \n",
    "                   padding='same'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Max Pooling\n",
    "Model_6.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_6.add(Dropout(0.40))\n",
    "\n",
    "# Flattening\n",
    "Model_6.add(Flatten())\n",
    "\n",
    "# Full Connection\n",
    "Model_6.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "# Adding Batch Normalization\n",
    "Model_6.add(BatchNormalization())\n",
    "\n",
    "# Adding Dropouts\n",
    "Model_6.add(Dropout(0.50))\n",
    "\n",
    "# Output Layer\n",
    "Model_6.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling Model_3\n",
    "Model_6.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation\n",
    "\n",
    "data_generator = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, \n",
    "                                    rotation_range = 20)\n",
    "train_set = data_generator.flow(x_train, y_train)\n",
    "steps = int(x_train.shape[0] / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 395s 253ms/step - loss: 1.5709 - accuracy: 0.4554 - val_loss: 1.1328 - val_accuracy: 0.5930\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 399s 255ms/step - loss: 1.0791 - accuracy: 0.6193 - val_loss: 0.8714 - val_accuracy: 0.6877\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.9062 - accuracy: 0.6860 - val_loss: 0.7677 - val_accuracy: 0.7321\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 402s 257ms/step - loss: 0.7972 - accuracy: 0.7263 - val_loss: 0.6749 - val_accuracy: 0.7674\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.7301 - accuracy: 0.7491 - val_loss: 0.6321 - val_accuracy: 0.7821\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.6710 - accuracy: 0.7715 - val_loss: 0.5846 - val_accuracy: 0.8002\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.6200 - accuracy: 0.7903 - val_loss: 0.5347 - val_accuracy: 0.8210\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.5884 - accuracy: 0.8010 - val_loss: 0.5332 - val_accuracy: 0.8176\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.5520 - accuracy: 0.8137 - val_loss: 0.5090 - val_accuracy: 0.8327\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.5247 - accuracy: 0.8196 - val_loss: 0.5089 - val_accuracy: 0.8311\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.5013 - accuracy: 0.8294 - val_loss: 0.5102 - val_accuracy: 0.8293\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 411s 263ms/step - loss: 0.4795 - accuracy: 0.8372 - val_loss: 0.4987 - val_accuracy: 0.8348\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.4600 - accuracy: 0.8422 - val_loss: 0.5005 - val_accuracy: 0.8358\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 408s 261ms/step - loss: 0.4394 - accuracy: 0.8494 - val_loss: 0.4877 - val_accuracy: 0.8367\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.4249 - accuracy: 0.8540 - val_loss: 0.4632 - val_accuracy: 0.8481\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.4123 - accuracy: 0.8609 - val_loss: 0.4572 - val_accuracy: 0.8523\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.4035 - accuracy: 0.8628 - val_loss: 0.4431 - val_accuracy: 0.8593\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.3881 - accuracy: 0.8677 - val_loss: 0.4434 - val_accuracy: 0.8547\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.3769 - accuracy: 0.8721 - val_loss: 0.4417 - val_accuracy: 0.8567\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.3702 - accuracy: 0.8754 - val_loss: 0.4655 - val_accuracy: 0.8480\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 411s 263ms/step - loss: 0.3580 - accuracy: 0.8765 - val_loss: 0.4119 - val_accuracy: 0.8625\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.3489 - accuracy: 0.8803 - val_loss: 0.4356 - val_accuracy: 0.8575\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.3417 - accuracy: 0.8813 - val_loss: 0.4711 - val_accuracy: 0.8521\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 408s 261ms/step - loss: 0.3298 - accuracy: 0.8876 - val_loss: 0.4400 - val_accuracy: 0.8574\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 408s 261ms/step - loss: 0.3288 - accuracy: 0.8879 - val_loss: 0.4765 - val_accuracy: 0.8500\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.3115 - accuracy: 0.8926 - val_loss: 0.4481 - val_accuracy: 0.8605\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 408s 261ms/step - loss: 0.3090 - accuracy: 0.8945 - val_loss: 0.4443 - val_accuracy: 0.8595\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.3077 - accuracy: 0.8945 - val_loss: 0.4467 - val_accuracy: 0.8601\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.2997 - accuracy: 0.8967 - val_loss: 0.4432 - val_accuracy: 0.8642\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 411s 263ms/step - loss: 0.2932 - accuracy: 0.8993 - val_loss: 0.4330 - val_accuracy: 0.8638\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 408s 261ms/step - loss: 0.2891 - accuracy: 0.8997 - val_loss: 0.4231 - val_accuracy: 0.8663\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 404s 259ms/step - loss: 0.2847 - accuracy: 0.9018 - val_loss: 0.4220 - val_accuracy: 0.8705\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 404s 259ms/step - loss: 0.2806 - accuracy: 0.9014 - val_loss: 0.4359 - val_accuracy: 0.8660\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 404s 258ms/step - loss: 0.2734 - accuracy: 0.9062 - val_loss: 0.4255 - val_accuracy: 0.8664\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2691 - accuracy: 0.9072 - val_loss: 0.4285 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.2666 - accuracy: 0.9091 - val_loss: 0.4222 - val_accuracy: 0.8663\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 404s 259ms/step - loss: 0.2632 - accuracy: 0.9091 - val_loss: 0.4637 - val_accuracy: 0.8589\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 409s 262ms/step - loss: 0.2569 - accuracy: 0.9108 - val_loss: 0.4418 - val_accuracy: 0.8632\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2528 - accuracy: 0.9122 - val_loss: 0.4316 - val_accuracy: 0.8665\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2516 - accuracy: 0.9126 - val_loss: 0.4427 - val_accuracy: 0.8659\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 409s 261ms/step - loss: 0.2466 - accuracy: 0.9163 - val_loss: 0.4926 - val_accuracy: 0.8558\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2409 - accuracy: 0.9160 - val_loss: 0.4373 - val_accuracy: 0.8679\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.2370 - accuracy: 0.9184 - val_loss: 0.4485 - val_accuracy: 0.8675\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 407s 260ms/step - loss: 0.2397 - accuracy: 0.9166 - val_loss: 0.4372 - val_accuracy: 0.8697\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2350 - accuracy: 0.9182 - val_loss: 0.4396 - val_accuracy: 0.8687\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 410s 262ms/step - loss: 0.2322 - accuracy: 0.9194 - val_loss: 0.4315 - val_accuracy: 0.8728\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 415s 266ms/step - loss: 0.2286 - accuracy: 0.9215 - val_loss: 0.4303 - val_accuracy: 0.8728\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.2230 - accuracy: 0.9228 - val_loss: 0.4315 - val_accuracy: 0.8710\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 405s 259ms/step - loss: 0.2250 - accuracy: 0.9213 - val_loss: 0.4606 - val_accuracy: 0.8668\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 406s 260ms/step - loss: 0.2247 - accuracy: 0.9230 - val_loss: 0.4837 - val_accuracy: 0.8569\n"
     ]
    }
   ],
   "source": [
    "Model_6_result = Model_6.fit(x_train, y_train, epochs = 50, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 16s 53ms/step - loss: 0.4837 - accuracy: 0.8569\n",
      "Test Loss is : 0.4836590886116028 and the Test Accuracy is: 0.8568999767303467\n"
     ]
    }
   ],
   "source": [
    "Model_6_evaluation = Model_6.evaluate(x_test, y_test)\n",
    "print('Test Loss is : {} and the Test Accuracy is: {}'.format(Model_6_evaluation[0], Model_6_evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image augmentation will always helps model to genearalize more. \n",
    "2. We are now getting 87.28% validation accuracy with 0.43 validation loss at 47th epoch.\n",
    "3. If we keep on increasing the Epoch then the accuracy might improve. But let us stop our exploration here and conclude the results. \n",
    "3. Later some other time we will explore the rest of the 12 percent accuracy!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 87.28 % accuracy is not bad and there is lot to try, we have pretrained models, we have complex architectures. Also we can gather more data. If we have good computational resources we can play with batch size and learning rate. Which we will explor in other note books.\n",
    "\n",
    "- This note book is a combination of multiple tutorials and different kaggle kernals. If you find this note books intresting run the code and play with parameters and see how it is behaving. If you know someother ways to improve accuracy beyond 87.28 please comment so that we can try.\n",
    "\n",
    "- I read that using pretrained model will improve the accuracy a lot since the models already have certain filters or layers that are good at recognizing certain image. We will try that in a different notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
